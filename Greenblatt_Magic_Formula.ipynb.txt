{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Greenblatt_Magic_Formula.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tjGr66FWqXCg",
        "k0SrRboVgejp"
      ],
      "authorship_tag": "ABX9TyNouQfGdOJ5cetND16sJKxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jesvin1/Udemy_Algo_Trading/blob/master/Greenblatt_Magic_Formula.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjGr66FWqXCg",
        "colab_type": "text"
      },
      "source": [
        "#Importing Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSV8VEVWqWHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ============================================================================\n",
        "# Greenblatt's Magic Formula Implementation\n",
        "# Author - Mayank Rasu\n",
        "\n",
        "# Please report bugs/issues in the Q&A section\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SelcYgwcqQZi",
        "colab_type": "text"
      },
      "source": [
        "#Getting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0SrRboVgejp",
        "colab_type": "text"
      },
      "source": [
        "## Small Cap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB2_QACTnoHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tickers = ['APLAPOLLO.NS','ADVENZYMES.NS','AEGISCHEM.NS','AFFLE.NS','ALKYLAMINE.NS','ALLCARGO.NS','AMBER.NS','ARVINDFASN.NS','ASAHIINDIA.NS',\n",
        "          'ASHOKA.NS','ASTERDM.NS','ASTRAZEN.NS','AVANTIFEED.NS','BASF.NS','BEML.NS','BSE.NS','BAJAJCON.NS','BAJAJELEC.NS','BALMLAWRIE.NS',\n",
        "          'BALRAMCHIN.NS','MAHABANK.NS','BDL.NS','BHARATRAS.NS','BIRLACORPN.NS','BSOFT.NS','BLISSGVS.NS','BLUESTARCO.NS','BOMDYEING.NS',\n",
        "          'BRIGADE.NS','CARERATING.NS','CCL.NS','CSBBANK.NS','CANFINHOME.NS','CAPLIPOINT.NS','CGCL.NS','CARBORUNIV.NS','CEATLTD.NS',\n",
        "          'CDSL.NS','CENTURYPLY.NS','CENTURYTEX.NS','CERA.NS','CHAMBLFERT.NS','CHENNPETRO.NS','COCHINSHIP.NS','CYIENT.NS','DBCORP.NS',\n",
        "'DCBBANK.NS','DCMSHRIRAM.NS','DEEPAKNTR.NS','DELTACORP.NS','DHANUKA.NS','DBL.NS','DISHTV.NS','DCAL.NS','DIXON.NS','EIDPARRY.NS','ESABINDIA.NS',\n",
        "'ELGIEQUIP.NS','ENGINERSIN.NS','EQUITAS.NS','ESSELPACK.NS','FDC.NS','FINEORG.NS','FINCABLES.NS','FINPIPE.NS','FSL.NS','FCONSUMER.NS','GEPIL.NS',\n",
        "'GET&D.NS','GHCL.NS','GMMPFAUDLR.NS','GALAXYSURF.NS','GRSE.NS','GARFIBRES.NS','GODFRYPHLP.NS','GRANULES.NS','GRAPHITE.NS','GESHIP.NS',\n",
        "'GREAVESCOT.NS','GRINDWELL.NS','GUJALKALI.NS','FLUOROCHEM.NS','GMDCLTD.NS','GNFC.NS','GPPL.NS','GSFC.NS','GULFOILLUB.NS','HEG.NS','HFCL.NS',\n",
        "'HATHWAY.NS','HEIDELBERG.NS','HERITGFOOD.NS','HSCL.NS','HIMATSEIDE.NS','HINDCOPPER.NS','ICRA.NS','IDFC.NS','IFBIND.NS','IFCI.NS','IIFL.NS',\n",
        "'IRB.NS','IRCON.NS','ITI.NS','INDIACEM.NS','ITDC.NS','IBREALEST.NS','INDIAMART.NS','INDIANB.NS','IEX.NS','INDOSTAR.NS','INDOCO.NS','INFIBEAM.NS',\n",
        "'INGERRAND.NS','INOXLEISUR.NS','INTELLECT.NS','JBCHEPHARM.NS','JKLAKSHMI.NS','JKPAPER.NS','JKTYRE.NS','JMFINANCIL.NS','JAGRAN.NS','JAICORPLTD.NS',\n",
        "'J&KBANK.NS','JAMNAAUTO.NS','JINDALSAW.NS','JSLHISAR.NS','JSL.NS','JCHAC.NS','JUSTDIAL.NS','JYOTHYLAB.NS','KPRMILL.NS','KEI.NS','KNRCON.NS',\n",
        "'KPITTECH.NS','KRBL.NS','KSB.NS','KAJARIACER.NS','KALPATPOWR.NS','KTKBANK.NS','KARURVYSYA.NS','KSCL.NS','KEC.NS','KOLTEPATIL.NS','LAOPALA.NS',\n",
        "'LAXMIMACH.NS','LAURUSLABS.NS','LEMONTREE.NS','LINDEINDIA.NS','LUXIND.NS','MASFIN.NS','MMTC.NS','MOIL.NS','MAHSCOOTER.NS','MAHSEAMLES.NS',\n",
        "'MAHINDCIE.NS','MHRIL.NS','MAHLOG.NS','METROPOLIS.NS','MINDACORP.NS','MIDHANI.NS','MCX.NS','NBCC.NS','NCC.NS','NESCO.NS','NH.NS',\n",
        "'NFL.NS','NBVENTURES.NS','NAVINFLUOR.NS','NILKAMAL.NS','OMAXE.NS','ORIENTCEM.NS','ORIENTELEC.NS','ORIENTREF.NS','PNCINFRA.NS','PTC.NS',\n",
        "'PVR.NS','PERSISTENT.NS','PHILIPCARB.NS','POLYMED.NS','PRAJIND.NS','PRSMJOHNSN.NS','PGHL.NS','RITES.NS','RADICO.NS','RVNL.NS','RAIN.NS',\n",
        "'RALLIS.NS','RCF.NS','RATNAMANI.NS','RAYMOND.NS','REDINGTON.NS','REPCOHOME.NS','SADBHAV.NS','SCHNEIDER.NS','SIS.NS','SEQUENT.NS','SFL.NS',\n",
        "'SCI.NS','SHOPERSTOP.NS','RENUKA.NS','SOBHA.NS','SONATSOFTW.NS','SOUTHBANK.NS','SPANDANA.NS','SPICEJET.NS','STARCEMENT.NS','SWSOLAR.NS',\n",
        "'STRTECH.NS','STAR.NS','SUDARSCHEM.NS','SPARC.NS','SUNTECK.NS','SUPRAJIT.NS','SUZLON.NS','SWANENERGY.NS','TCIEXP.NS','TCNSBRANDS.NS',\n",
        "'TVTODAY.NS','TV18BRDCST.NS','TAKE.NS','TASTYBITE.NS','TATAELXSI.NS','TATAINVEST.NS','TATASTLBSL.NS','TEAMLEASE.NS','THYROCARE.NS',\n",
        "'TIMETECHNO.NS','TIMKEN.NS','TRIDENT.NS','TIINDIA.NS','UFLEX.NS','UJJIVAN.NS','UJJIVANSFB.NS','VMART.NS','VIPIND.NS','VRLLOG.NS',\n",
        "'VSTIND.NS','VAIBHAVGBL.NS','VAKRANGEE.NS','VTL.NS','VARROC.NS','VENKEYS.NS','VESUVIUS.NS','WELCORP.NS','WELSPUNIND.NS','WESTLIFE.NS',\n",
        "'WOCKPHARMA.NS','ZENSARTECH.NS','ZYDUSWELL.NS','ECLERX.NS']\n",
        "\n",
        "#list of tickers whose financial data needs to be extracted\n",
        "financial_dir = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj7wBhPlg1EI",
        "colab_type": "text"
      },
      "source": [
        "## Mid Cap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4I6Wsptg5Jd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list of tickers whose financial data needs to be extracted\n",
        "tickers = ['ADANIPOWER.NS','AMARAJABAT.NS','APOLLOHOSP.NS','APOLLOTYRE.NS','ASHOKLEY.NS','BALKRISIND.NS','BANKINDIA.NS','BATAINDIA.NS',\n",
        "'BEL.NS','BHARATFORG.NS','BHEL.NS','CESC.NS','CANBK.NS','CASTROLIND.NS','CHOLAFIN.NS','CUMMINSIND.NS','ESCORTS.NS','EXIDEIND.NS',\n",
        "'FEDERALBNK.NS','GMRINFRA.NS','GLENMARK.NS','GODREJPROP.NS','HEXAWARE.NS','IDFCFIRSTB.NS','IBULHSGFIN.NS','JINDALSTEL.NS','JUBLFOOD.NS',\n",
        "'L&TFH.NS','LICHSGFIN.NS','MRF.NS','MGL.NS','M&MFIN.NS','MANAPPURAM.NS','MFSL.NS','MINDTREE.NS','NATIONALUM.NS','OIL.NS','RBLBANK.NS',\n",
        "'RECLTD.NS','SRF.NS','SAIL.NS','SUNTV.NS','TVSMOTOR.NS','TATACONSUM.NS','TATAPOWER.NS','RAMCOCEM.NS','TORNTPOWER.NS','UNIONBANK.NS',\n",
        "'IDEA.NS','VOLTAS.NS']\n",
        "\n",
        "\n",
        "financial_dir = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdFyq-y1gr4B",
        "colab_type": "text"
      },
      "source": [
        "# Maths "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQKe5vumtygO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ticker in tickers:\n",
        "    try:\n",
        "    #getting balance sheet data from yahoo finance for the given ticker\n",
        "        temp_dir = {}\n",
        "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/balance-sheet?p='+ticker\n",
        "        page = requests.get(url)\n",
        "        page_content = page.content\n",
        "        soup = BeautifulSoup(page_content,'html.parser')\n",
        "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
        "        for t in tabl:\n",
        "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
        "            for row in rows:\n",
        "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
        "        \n",
        "        #getting income statement data from yahoo finance for the given ticker\n",
        "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/financials?p='+ticker\n",
        "        page = requests.get(url)\n",
        "        page_content = page.content\n",
        "        soup = BeautifulSoup(page_content,'html.parser')\n",
        "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
        "        for t in tabl:\n",
        "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
        "            for row in rows:\n",
        "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
        "        \n",
        "        #getting cashflow statement data from yahoo finance for the given ticker\n",
        "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/cash-flow?p='+ticker\n",
        "        page = requests.get(url)\n",
        "        page_content = page.content\n",
        "        soup = BeautifulSoup(page_content,'html.parser')\n",
        "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
        "        for t in tabl:\n",
        "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
        "            for row in rows:\n",
        "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
        "        \n",
        "        #getting key statistics data from yahoo finance for the given ticker\n",
        "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/key-statistics?p='+ticker\n",
        "        page = requests.get(url)\n",
        "        page_content = page.content\n",
        "        soup = BeautifulSoup(page_content,'html.parser')\n",
        "        tabl = soup.findAll(\"table\", {\"class\": \"W(100%) Bdcl(c) \"}) # try soup.findAll(\"table\") if this line gives error \n",
        "        for t in tabl:\n",
        "            rows = t.find_all(\"tr\")\n",
        "            for row in rows:\n",
        "                if len(row.get_text(separator='|').split(\"|\")[0:2])>0:\n",
        "                    temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[-1]    \n",
        "        \n",
        "        #combining all extracted information with the corresponding ticker\n",
        "        financial_dir[ticker] = temp_dir\n",
        "    except:\n",
        "        print(\"Problem scraping data for \",ticker)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHYitqgat_27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#storing information in pandas dataframe\n",
        "combined_financials = pd.DataFrame(financial_dir)\n",
        "combined_financials.dropna(how='all',axis=1,inplace=True) #dropping columns with all NaN values\n",
        "tickers = combined_financials.columns #updating the tickers list based on only those tickers whose values were successfully extracted\n",
        "for ticker in tickers:\n",
        "    combined_financials = combined_financials[~combined_financials[ticker].str.contains(\"[a-z]\").fillna(False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQAnIF5EuPUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating dataframe with relevant financial information for each stock using fundamental data\n",
        "stats = [\"EBITDA\",\n",
        "         \"Depreciation & amortisation\",\n",
        "         \"Market cap (intra-day)\",\n",
        "         \"Net income available to common shareholders\",\n",
        "         \"Net cash provided by operating activities\",\n",
        "         \"Capital expenditure\",\n",
        "         \"Total current assets\",\n",
        "         \"Total current liabilities\",\n",
        "         \"Net property, plant and equipment\",\n",
        "         \"Total stockholders' equity\",\n",
        "         \"Long-term debt\",\n",
        "         \"Forward annual dividend yield\"] # change as required\n",
        "\n",
        "indx = [\"EBITDA\",\"D&A\",\"MarketCap\",\"NetIncome\",\"CashFlowOps\",\"Capex\",\"CurrAsset\",\n",
        "        \"CurrLiab\",\"PPE\",\"BookValue\",\"TotDebt\",\"DivYield\"]\n",
        "all_stats = {}\n",
        "for ticker in tickers:\n",
        "    try:\n",
        "        temp = combined_financials[ticker]\n",
        "        ticker_stats = []\n",
        "        for stat in stats:\n",
        "            ticker_stats.append(temp.loc[stat])\n",
        "        all_stats['{}'.format(ticker)] = ticker_stats\n",
        "    except:\n",
        "        print(\"can't read data for \",ticker)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndD4qvB2uX0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cleansing of fundamental data imported in dataframe\n",
        "all_stats_df = pd.DataFrame(all_stats,index=indx)\n",
        "all_stats_df[tickers] = all_stats_df[tickers].replace({',': ''}, regex=True)\n",
        "all_stats_df[tickers] = all_stats_df[tickers].replace({'M': 'E+03'}, regex=True)\n",
        "all_stats_df[tickers] = all_stats_df[tickers].replace({'B': 'E+06'}, regex=True)\n",
        "all_stats_df[tickers] = all_stats_df[tickers].replace({'T': 'E+09'}, regex=True)\n",
        "all_stats_df[tickers] = all_stats_df[tickers].replace({'%': 'E-02'}, regex=True)\n",
        "for ticker in all_stats_df.columns:\n",
        "    all_stats_df[ticker] = pd.to_numeric(all_stats_df[ticker].values,errors='coerce')\n",
        "all_stats_df.dropna(axis=1,inplace=True)\n",
        "tickers = all_stats_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAVfHtIouhfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculating relevant financial metrics for each stock\n",
        "transpose_df = all_stats_df.transpose()\n",
        "final_stats_df = pd.DataFrame()\n",
        "final_stats_df[\"EBIT\"] = transpose_df[\"EBITDA\"] - transpose_df[\"D&A\"]\n",
        "final_stats_df[\"TEV\"] =  transpose_df[\"MarketCap\"].fillna(0) \\\n",
        "                         +transpose_df[\"TotDebt\"].fillna(0) \\\n",
        "                         -(transpose_df[\"CurrAsset\"].fillna(0)-transpose_df[\"CurrLiab\"].fillna(0))\n",
        "final_stats_df[\"EarningYield\"] =  final_stats_df[\"EBIT\"]/final_stats_df[\"TEV\"]\n",
        "final_stats_df[\"FCFYield\"] = (transpose_df[\"CashFlowOps\"]-transpose_df[\"Capex\"])/transpose_df[\"MarketCap\"]\n",
        "final_stats_df[\"ROC\"]  = (transpose_df[\"EBITDA\"] - transpose_df[\"D&A\"])/(transpose_df[\"PPE\"]+transpose_df[\"CurrAsset\"]-transpose_df[\"CurrLiab\"])\n",
        "final_stats_df[\"BookToMkt\"] = transpose_df[\"BookValue\"]/transpose_df[\"MarketCap\"]\n",
        "final_stats_df[\"DivYield\"] = transpose_df[\"DivYield\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z5KTESSulBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "a9a06122-425a-46e7-820a-344812b740fc"
      },
      "source": [
        "################################Output Dataframes##############################\n",
        "\n",
        "# finding value stocks based on Magic Formula\n",
        "final_stats_val_df = final_stats_df.loc[tickers,:]\n",
        "final_stats_val_df[\"CombRank\"] = final_stats_val_df[\"EarningYield\"].rank(ascending=False,na_option='bottom')+final_stats_val_df[\"ROC\"].rank(ascending=False,na_option='bottom')\n",
        "final_stats_val_df[\"MagicFormulaRank\"] = final_stats_val_df[\"CombRank\"].rank(method='first')\n",
        "value_stocks = final_stats_val_df.sort_values(\"MagicFormulaRank\").iloc[:,[2,4,8]]\n",
        "print(\"------------------------------------------------\")\n",
        "print(\"Value stocks based on Greenblatt's Magic Formula\")\n",
        "print(value_stocks)\n",
        "\n",
        "\n",
        "# finding highest dividend yield stocks\n",
        "high_dividend_stocks = final_stats_df.sort_values(\"DivYield\",ascending=False).iloc[:,6]\n",
        "print(\"------------------------------------------------\")\n",
        "print(\"Highest dividend paying stocks\")\n",
        "print(high_dividend_stocks)\n",
        "\n",
        "\n",
        "# # Magic Formula & Dividend yield combined\n",
        "final_stats_df[\"CombRank\"] = final_stats_df[\"EarningYield\"].rank(ascending=False,method='first') \\\n",
        "                              +final_stats_df[\"ROC\"].rank(ascending=False,method='first')  \\\n",
        "                              +final_stats_df[\"DivYield\"].rank(ascending=False,method='first')\n",
        "final_stats_df[\"CombinedRank\"] = final_stats_df[\"CombRank\"].rank(method='first')\n",
        "value_high_div_stocks = final_stats_df.sort_values(\"CombinedRank\").iloc[:,[2,4,6,8]]\n",
        "print(\"------------------------------------------------\")\n",
        "print(\"Magic Formula and Dividend Yield combined\")\n",
        "print(value_high_div_stocks)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------\n",
            "Value stocks based on Greenblatt's Magic Formula\n",
            "               EarningYield       ROC  MagicFormulaRank\n",
            "TVSMOTOR.NS        0.068097  0.431050               1.0\n",
            "AMARAJABAT.NS      0.073256  0.211219               2.0\n",
            "MINDTREE.NS        0.057386  0.314011               3.0\n",
            "CESC.NS            0.113039  0.096086               4.0\n",
            "TATAPOWER.NS       0.096072  0.137887               5.0\n",
            "TORNTPOWER.NS      0.100450  0.126308               6.0\n",
            "BALKRISIND.NS      0.037822  0.215405               7.0\n",
            "TATACONSUM.NS      0.027919  0.183162               8.0\n",
            "------------------------------------------------\n",
            "Highest dividend paying stocks\n",
            "TORNTPOWER.NS    0.0519\n",
            "CESC.NS          0.0343\n",
            "TATAPOWER.NS     0.0310\n",
            "BALKRISIND.NS    0.0173\n",
            "MINDTREE.NS      0.0168\n",
            "AMARAJABAT.NS    0.0154\n",
            "TVSMOTOR.NS      0.0069\n",
            "TATACONSUM.NS    0.0067\n",
            "Name: DivYield, dtype: float64\n",
            "------------------------------------------------\n",
            "Magic Formula and Dividend Yield combined\n",
            "               EarningYield       ROC  DivYield  CombinedRank\n",
            "TORNTPOWER.NS      0.100450  0.126308    0.0519           1.0\n",
            "CESC.NS            0.113039  0.096086    0.0343           2.0\n",
            "TATAPOWER.NS       0.096072  0.137887    0.0310           3.0\n",
            "MINDTREE.NS        0.057386  0.314011    0.0168           4.0\n",
            "TVSMOTOR.NS        0.068097  0.431050    0.0069           5.0\n",
            "AMARAJABAT.NS      0.073256  0.211219    0.0154           6.0\n",
            "BALKRISIND.NS      0.037822  0.215405    0.0173           7.0\n",
            "TATACONSUM.NS      0.027919  0.183162    0.0067           8.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}