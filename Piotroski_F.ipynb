{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Piotroski_F.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4At4c0t3C61IsIGBL8HNt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jesvin1/Basics/blob/master/Piotroski_F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWaS1vc6H28O",
        "colab_type": "text"
      },
      "source": [
        "# Importing Package and intro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK3yXpn4G--d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ============================================================================\n",
        "# Piotroski f score implementation (data scraped from yahoo finance)\n",
        "# Author - Mayank Rasu\n",
        "\n",
        "# Please report bugs/issues in the Q&A section\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8V3qY6ZIQ5C",
        "colab_type": "text"
      },
      "source": [
        "# Getting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw61imdWIYS_",
        "colab_type": "text"
      },
      "source": [
        "##Mid Cap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rF-uhWlIUIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#list of tickers whose financial data needs to be extracted\n",
        "tickers = ['ADANIPOWER.NS','AMARAJABAT.NS','APOLLOHOSP.NS','APOLLOTYRE.NS','ASHOKLEY.NS','BALKRISIND.NS','BANKINDIA.NS','BATAINDIA.NS',\n",
        "'BEL.NS','BHARATFORG.NS','BHEL.NS','CESC.NS','CANBK.NS','CASTROLIND.NS','CHOLAFIN.NS','CUMMINSIND.NS','ESCORTS.NS','EXIDEIND.NS',\n",
        "'FEDERALBNK.NS','GMRINFRA.NS','GLENMARK.NS','GODREJPROP.NS','HEXAWARE.NS','IDFCFIRSTB.NS','IBULHSGFIN.NS','JINDALSTEL.NS','JUBLFOOD.NS',\n",
        "'L&TFH.NS','LICHSGFIN.NS','MRF.NS','MGL.NS','M&MFIN.NS','MANAPPURAM.NS','MFSL.NS','MINDTREE.NS','NATIONALUM.NS','OIL.NS','RBLBANK.NS',\n",
        "'RECLTD.NS','SRF.NS','SAIL.NS','SUNTV.NS','TVSMOTOR.NS','TATACONSUM.NS','TATAPOWER.NS','RAMCOCEM.NS','TORNTPOWER.NS','UNIONBANK.NS',\n",
        "'IDEA.NS','VOLTAS.NS']\n",
        "\n",
        "#list of tickers whose financial data needs to be extracted\n",
        "financial_dir_cy = {} #directory to store current year's information\n",
        "financial_dir_py = {} #directory to store last year's information\n",
        "financial_dir_py2 = {} #directory to store last to last year's information"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VtUHc_yIcjr",
        "colab_type": "text"
      },
      "source": [
        "# Maths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR_8C7R8If7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7563c57c-92c3-4c6e-9c1e-6714b5dfbf8e"
      },
      "source": [
        "for ticker in tickers:\n",
        "    try:\n",
        "        print(\"scraping financial statement data for \",ticker)\n",
        "        temp_dir = {}\n",
        "        temp_dir2 = {}\n",
        "        temp_dir3 = {}\n",
        "    #getting balance sheet data from yahoo finance for the given ticker\n",
        "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/balance-sheet?p='+ticker\n",
        "        page = requests.get(url)\n",
        "        page_content = page.content\n",
        "        soup = BeautifulSoup(page_content,'html.parser')\n",
        "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
        "        for t in tabl:\n",
        "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
        "            for row in rows:\n",
        "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
        "                temp_dir2[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[2]\n",
        "                temp_dir3[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[3]\n",
        "        \n",
        "        #getting income statement data from yahoo finance for the given ticker\n",
        "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/financials?p='+ticker\n",
        "        page = requests.get(url)\n",
        "        page_content = page.content\n",
        "        soup = BeautifulSoup(page_content,'html.parser')\n",
        "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
        "        for t in tabl:\n",
        "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
        "            for row in rows:\n",
        "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
        "                temp_dir2[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[2]\n",
        "                temp_dir3[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[3]\n",
        "        \n",
        "        #getting cashflow statement data from yahoo finance for the given ticker\n",
        "        url = 'https://in.finance.yahoo.com/quote/'+ticker+'/cash-flow?p='+ticker\n",
        "        page = requests.get(url)\n",
        "        page_content = page.content\n",
        "        soup = BeautifulSoup(page_content,'html.parser')\n",
        "        tabl = soup.find_all(\"div\", {\"class\" : \"M(0) Whs(n) BdEnd Bdc($seperatorColor) D(itb)\"})\n",
        "        for t in tabl:\n",
        "            rows = t.find_all(\"div\", {\"class\" : \"rw-expnded\"})\n",
        "            for row in rows:\n",
        "                temp_dir[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[1]\n",
        "                temp_dir2[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[2]\n",
        "                temp_dir3[row.get_text(separator='|').split(\"|\")[0]]=row.get_text(separator='|').split(\"|\")[3] \n",
        "        \n",
        "        #combining all extracted information with the corresponding ticker\n",
        "        financial_dir_cy[ticker] = temp_dir\n",
        "        financial_dir_py[ticker] = temp_dir2\n",
        "        financial_dir_py2[ticker] = temp_dir3\n",
        "    except:\n",
        "        print(\"Problem scraping data for \",ticker)\n",
        "\n",
        "\n",
        "#storing information in pandas dataframe\n",
        "combined_financials_cy = pd.DataFrame(financial_dir_cy)\n",
        "#combined_financials_cy.dropna(axis=1,inplace=True) #dropping columns with NaN values\n",
        "combined_financials_py = pd.DataFrame(financial_dir_py)\n",
        "#combined_financials_py.dropna(axis=1,inplace=True)\n",
        "combined_financials_py2 = pd.DataFrame(financial_dir_py2)\n",
        "#combined_financials_py2.dropna(axis=1,inplace=True)\n",
        "tickers = combined_financials_cy.columns #updating the tickers list based on only those tickers whose values were successfully extracted\n",
        "\n",
        "# selecting relevant financial information for each stock using fundamental data\n",
        "stats = [\"Net income available to common shareholders\",\n",
        "         \"Total assets\",\n",
        "         \"Net cash provided by operating activities\",\n",
        "         \"Long-term debt\",\n",
        "         \"Other long-term liabilities\",\n",
        "         \"Total current assets\",\n",
        "         \"Total current liabilities\",\n",
        "         \"Common stock\",\n",
        "         \"Total revenue\",\n",
        "         \"Gross profit\"] # change as required\n",
        "\n",
        "indx = [\"NetIncome\",\"TotAssets\",\"CashFlowOps\",\"LTDebt\",\"OtherLTDebt\",\n",
        "        \"CurrAssets\",\"CurrLiab\",\"CommStock\",\"TotRevenue\",\"GrossProfit\"]\n",
        "\n",
        "\n",
        "def info_filter(df,stats,indx):\n",
        "    \"\"\"function to filter relevant financial information for each \n",
        "       stock and transforming string inputs to numeric\"\"\"\n",
        "    tickers = df.columns\n",
        "    all_stats = {}\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            temp = df[ticker]\n",
        "            ticker_stats = []\n",
        "            for stat in stats:\n",
        "                ticker_stats.append(temp.loc[stat])\n",
        "            all_stats['{}'.format(ticker)] = ticker_stats\n",
        "        except:\n",
        "            print(\"can't read data for \",ticker)\n",
        "    \n",
        "    all_stats_df = pd.DataFrame(all_stats,index=indx)\n",
        "    \n",
        "    # cleansing of fundamental data imported in dataframe\n",
        "    all_stats_df[tickers] = all_stats_df[tickers].replace({',': ''}, regex=True)\n",
        "    for ticker in all_stats_df.columns:\n",
        "        all_stats_df[ticker] = pd.to_numeric(all_stats_df[ticker].values,errors='coerce')\n",
        "    return all_stats_df\n",
        "\n",
        "def piotroski_f(df_cy,df_py,df_py2):\n",
        "    \"\"\"function to calculate f score of each stock and output information as dataframe\"\"\"\n",
        "    f_score = {}\n",
        "    tickers = df_cy.columns\n",
        "    for ticker in tickers:\n",
        "        ROA_FS = int(df_cy.loc[\"NetIncome\",ticker]/((df_cy.loc[\"TotAssets\",ticker]+df_py.loc[\"TotAssets\",ticker])/2) > 0)\n",
        "        CFO_FS = int(df_cy.loc[\"CashFlowOps\",ticker] > 0)\n",
        "        ROA_D_FS = int(df_cy.loc[\"NetIncome\",ticker]/(df_cy.loc[\"TotAssets\",ticker]+df_py.loc[\"TotAssets\",ticker])/2 > df_py.loc[\"NetIncome\",ticker]/(df_py.loc[\"TotAssets\",ticker]+df_py2.loc[\"TotAssets\",ticker])/2)\n",
        "        CFO_ROA_FS = int(df_cy.loc[\"CashFlowOps\",ticker]/df_cy.loc[\"TotAssets\",ticker] > df_cy.loc[\"NetIncome\",ticker]/((df_cy.loc[\"TotAssets\",ticker]+df_py.loc[\"TotAssets\",ticker])/2))\n",
        "        LTD_FS = int((df_cy.loc[\"LTDebt\",ticker] + df_cy.loc[\"OtherLTDebt\",ticker])<(df_py.loc[\"LTDebt\",ticker] + df_py.loc[\"OtherLTDebt\",ticker]))\n",
        "        CR_FS = int((df_cy.loc[\"CurrAssets\",ticker]/df_cy.loc[\"CurrLiab\",ticker])>(df_py.loc[\"CurrAssets\",ticker]/df_py.loc[\"CurrLiab\",ticker]))\n",
        "        DILUTION_FS = int(df_cy.loc[\"CommStock\",ticker] <= df_py.loc[\"CommStock\",ticker])\n",
        "        GM_FS = int((df_cy.loc[\"GrossProfit\",ticker]/df_cy.loc[\"TotRevenue\",ticker])>(df_py.loc[\"GrossProfit\",ticker]/df_py.loc[\"TotRevenue\",ticker]))\n",
        "        ATO_FS = int(df_cy.loc[\"TotRevenue\",ticker]/((df_cy.loc[\"TotAssets\",ticker]+df_py.loc[\"TotAssets\",ticker])/2)>df_py.loc[\"TotRevenue\",ticker]/((df_py.loc[\"TotAssets\",ticker]+df_py2.loc[\"TotAssets\",ticker])/2))\n",
        "        f_score[ticker] = [ROA_FS,CFO_FS,ROA_D_FS,CFO_ROA_FS,LTD_FS,CR_FS,DILUTION_FS,GM_FS,ATO_FS]\n",
        "    f_score_df = pd.DataFrame(f_score,index=[\"PosROA\",\"PosCFO\",\"ROAChange\",\"Accruals\",\"Leverage\",\"Liquidity\",\"Dilution\",\"GM\",\"ATO\"])\n",
        "    return f_score_df\n",
        "\n",
        "# Selecting stocks with highest Piotroski f score\n",
        "transformed_df_cy = info_filter(combined_financials_cy,stats,indx)\n",
        "transformed_df_py = info_filter(combined_financials_py,stats,indx)\n",
        "transformed_df_py2 = info_filter(combined_financials_py2,stats,indx)\n",
        "\n",
        "f_score_df = piotroski_f(transformed_df_cy,transformed_df_py,transformed_df_py2)\n",
        "f_score_df.sum().sort_values(ascending=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "scraping financial statement data for  ADANIPOWER.NS\n",
            "scraping financial statement data for  AMARAJABAT.NS\n",
            "scraping financial statement data for  APOLLOHOSP.NS\n",
            "scraping financial statement data for  APOLLOTYRE.NS\n",
            "scraping financial statement data for  ASHOKLEY.NS\n",
            "scraping financial statement data for  BALKRISIND.NS\n",
            "scraping financial statement data for  BANKINDIA.NS\n",
            "scraping financial statement data for  BATAINDIA.NS\n",
            "scraping financial statement data for  BEL.NS\n",
            "scraping financial statement data for  BHARATFORG.NS\n",
            "scraping financial statement data for  BHEL.NS\n",
            "scraping financial statement data for  CESC.NS\n",
            "scraping financial statement data for  CANBK.NS\n",
            "scraping financial statement data for  CASTROLIND.NS\n",
            "scraping financial statement data for  CHOLAFIN.NS\n",
            "scraping financial statement data for  CUMMINSIND.NS\n",
            "scraping financial statement data for  ESCORTS.NS\n",
            "scraping financial statement data for  EXIDEIND.NS\n",
            "scraping financial statement data for  FEDERALBNK.NS\n",
            "scraping financial statement data for  GMRINFRA.NS\n",
            "scraping financial statement data for  GLENMARK.NS\n",
            "scraping financial statement data for  GODREJPROP.NS\n",
            "scraping financial statement data for  HEXAWARE.NS\n",
            "scraping financial statement data for  IDFCFIRSTB.NS\n",
            "scraping financial statement data for  IBULHSGFIN.NS\n",
            "scraping financial statement data for  JINDALSTEL.NS\n",
            "scraping financial statement data for  JUBLFOOD.NS\n",
            "scraping financial statement data for  L&TFH.NS\n",
            "scraping financial statement data for  LICHSGFIN.NS\n",
            "scraping financial statement data for  MRF.NS\n",
            "scraping financial statement data for  MGL.NS\n",
            "scraping financial statement data for  M&MFIN.NS\n",
            "scraping financial statement data for  MANAPPURAM.NS\n",
            "scraping financial statement data for  MFSL.NS\n",
            "scraping financial statement data for  MINDTREE.NS\n",
            "scraping financial statement data for  NATIONALUM.NS\n",
            "scraping financial statement data for  OIL.NS\n",
            "scraping financial statement data for  RBLBANK.NS\n",
            "scraping financial statement data for  RECLTD.NS\n",
            "scraping financial statement data for  SRF.NS\n",
            "scraping financial statement data for  SAIL.NS\n",
            "scraping financial statement data for  SUNTV.NS\n",
            "scraping financial statement data for  TVSMOTOR.NS\n",
            "scraping financial statement data for  TATACONSUM.NS\n",
            "scraping financial statement data for  TATAPOWER.NS\n",
            "scraping financial statement data for  RAMCOCEM.NS\n",
            "scraping financial statement data for  TORNTPOWER.NS\n",
            "scraping financial statement data for  UNIONBANK.NS\n",
            "scraping financial statement data for  IDEA.NS\n",
            "scraping financial statement data for  VOLTAS.NS\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CESC.NS          7\n",
              "ADANIPOWER.NS    5\n",
              "TORNTPOWER.NS    5\n",
              "TATAPOWER.NS     5\n",
              "APOLLOHOSP.NS    5\n",
              "MGL.NS           5\n",
              "BALKRISIND.NS    5\n",
              "MINDTREE.NS      5\n",
              "GMRINFRA.NS      4\n",
              "MRF.NS           4\n",
              "ESCORTS.NS       4\n",
              "CASTROLIND.NS    4\n",
              "GODREJPROP.NS    4\n",
              "BATAINDIA.NS     4\n",
              "APOLLOTYRE.NS    4\n",
              "RAMCOCEM.NS      4\n",
              "AMARAJABAT.NS    4\n",
              "HEXAWARE.NS      3\n",
              "BEL.NS           3\n",
              "CUMMINSIND.NS    3\n",
              "ASHOKLEY.NS      3\n",
              "EXIDEIND.NS      3\n",
              "GLENMARK.NS      3\n",
              "BHARATFORG.NS    3\n",
              "VOLTAS.NS        3\n",
              "SRF.NS           3\n",
              "JUBLFOOD.NS      3\n",
              "SUNTV.NS         3\n",
              "TATACONSUM.NS    3\n",
              "MANAPPURAM.NS    3\n",
              "SAIL.NS          3\n",
              "TVSMOTOR.NS      3\n",
              "IDFCFIRSTB.NS    2\n",
              "RECLTD.NS        2\n",
              "BHEL.NS          2\n",
              "OIL.NS           2\n",
              "MFSL.NS          2\n",
              "NATIONALUM.NS    2\n",
              "M&MFIN.NS        2\n",
              "LICHSGFIN.NS     2\n",
              "JINDALSTEL.NS    2\n",
              "UNIONBANK.NS     1\n",
              "IDEA.NS          1\n",
              "CANBK.NS         1\n",
              "BANKINDIA.NS     1\n",
              "RBLBANK.NS       1\n",
              "CHOLAFIN.NS      1\n",
              "FEDERALBNK.NS    1\n",
              "L&TFH.NS         1\n",
              "IBULHSGFIN.NS    1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0NCeZmJIt-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}